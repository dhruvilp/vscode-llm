{
    "name": "llm-bridge-extension",
    "displayName": "LLM Bridge Extension",
    "description": "Exposes VS Code's LLM capabilities via a local HTTP server.",
    "version": "0.0.1",
    "publisher": "vscode-llm-bridge",
    "engines": {
        "vscode": "^1.85.0"
    },
    "activationEvents": [
        "onCommand:llm-chat-example.askLlm"
    ],
    "main": "./out/extension.js",
    "contributes": {
        "commands": [
            {
                "command": "llm-chat-example.askLlm",
                "title": "Ask Language Model",
                "category": "LLM Example"
            }
        ]
    },
    "scripts": {
        "vscode:prepublish": "npm run compile",
        "compile": "tsc -p ./",
        "watch": "tsc -watch -p ./"
    },
    "devDependencies": {
        "@types/node": "^18.19.103",
        "@types/vscode": "^1.85.0",
        "typescript": "^5.8.3"
    },
    "dependencies": {
        "dotenv": "^16.5.0",
        "openai": "^4.103.0"
    }
}
